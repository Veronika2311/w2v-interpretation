{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнение качества POS-теггеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. найти или самим написать **русский и английский тексты (каждый от ста слов)**, в которых будут какие-то трудные или неоднозначные для POS теггинга моменты, **разметить их вручную, объяснить**, какие моменты вы считаете трудными для автоматического посттеггинга и почему. Размечаем только части речи.\n",
    "*балл за создание, разметку текста и объяснение, почему этот текст подходит для оценки (что в нём сложного). 2 балла*\n",
    "2. **три POS-теггера для русского** (pymorphy2, mysteam, Natasha) и **3  - для английского** (SpyCy, Flair, NLTK), прогнать текст через каждый из них \n",
    "*если вы запустите только 2 теггера из трёх – получите балл, если три из трёх – 2 балла, т. е. суммарно за этот пункт можно получить 4 балла*\n",
    "3. **оценить accuracy** для каждого теггера. В разных системах имена теггов и части речи могут отличаться, – вам надо будет свести это всё к единому стандарту с помощью какой-то функции или кода и сравнить с вашим размеченным руками эталоном - тоже с помощью какого-то кода или функции. \n",
    "*Этот пункт стоит 2 балла.\n",
    "Тут вы уже получили 8 баллов*\n",
    "4. взять лучший теггер для русского языка и с его помощью написать **функцию, которая повысит качество работы программы из первой домашки**. Так, многие из вас справедливо заметили, что если бы мы могли класть в словарь не только отдельные слова, но и словосочетания, то программа работала бы лучше. Вам надо выделить 3 вида синтаксических групп (к примеру не + какая-то часть речи или NP или сущ.+ наречие или еще что-то), запись которых в словарь, по вашему мнению, улучшила бы качество работы программы и создать такую функцию или функции, которые с помощью любых известных нам средств (chunking и regexp grammar, Natasha syntax parser, код с последнего занятия по SpyCy, etc.) будет выделять эти группы в поданном в нее тексте. \n",
    "*Два балла за саму функцию, балл за объяснение того, почему именно эти группы вы взяли*\n",
    "5. **Встроить эту функцию в программу** из предыдущей домашки и **сравните качества работы** программы с нею и без неё \n",
    "*2 бонусных*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Русский язык"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку у разных теггеров очень разные системы тегов, мы сведём их к максимально общим категориям. Например, выделим А как категорию наречий и прилагательных. Почему не отдельно? Вещи типа \"лучше\" один теггер считает компаративами, второй прилагательными, третий наречиями. Таким образом, наши классы состоят из A, V, S и ещё нескольких более-иенее универсальных классов. К идеалу привести, конечно же, не получится, так как некоторые категории могут пересекаться непредсказуемо, и чтобы исключить это пересечение, необходимо было бы объединить слишком много."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT1 = '''Отсутствующих людей в классе отмечать было не принято. Считать это злой волей или намеренным вредительством \n",
    "    не было причин, по крайней мере тех, которые можно было бы привести в пример, но это все равно казалось странноватым. \n",
    "    Достаточно, чтобы задуматься и по-новому оценить по-старому организованный порядок. Несмотря на то, что лишь прыгнув, \n",
    "    можно было получить замечание, из-за пропусков завучиха не возникала. Школьный трудовик Иван пытался было возразить, дескать,\n",
    "    все не по ГОСТу и Минобр будет недобр, но куда там - в принципе, пока никто не косячил, несуразица никого особо \n",
    "    не трогала. Де-юре все было чин по чину, де-факто же дисциплина страдала нещадно, и даже разговоры тет-а-тет \n",
    "    в директорской приемной не сильно спасали неуклонно падающий псевдоавторитет учительского состава. Ой-ой-ой.\n",
    "    Зимой было чуть лучше, но за зимой пришла весна, и тут стало интереснее: в апреле появился не только запах ландышей. \n",
    "    Апрель запах проблемами.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот текст неплох для того, чтобы проверять теггеры по нему, так как здесь не каждое место сложное, но их достаточно. К примеру, разметка прилагательных, причастий и субстантивированных существительных. \"Директорская\" и \"приёмная\" выглядят одинаково, однако второе хотелось бы видеть размеченным как сууществительное, а первое -- как нечто прилагательноподобное. К тому же, здесь достаточно сокращений (завучиха, трудовик), омонимии (запах), наречий с дефисом внутри (де-юре), новообразованных слов (псевдоавторитет), аббревиатур (Минобр), кратких прилагательных (недобр). \n",
    "\n",
    "\n",
    "Проблему в ручной разметке составляют те же самые вводные, а также частицы. Было бы сложно в каких-то случаях точно определить принадлежность слова к части речи. К примеру, как бы мы хотели, чтобы программы анализировали слова типа \"чин по чину\"? Хотелось бы сказать, конечно, что это наречие, но вряд ли наши морфологизаторы это поймут. То же самое касается вещей типа \"куда там\" -- определить части речи в этом устоявшемся выражнении сложно. Поскольку, в отличие от авторов преддущего ридинга, не имела возможноти посоветоваться с командой эксперотов, то и разметила всё по разумению своему. Надеюсь, здесь не будет оцениваться качество меня как морфоразметчика. Да простят меня проверяющие за длинные переменные с разбором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT = [{'слово': 'отсутствующих', 'разбор': 'A'},\n",
    " {'слово': 'людей', 'разбор': 'N'},\n",
    " {'слово': 'в', 'разбор': 'PREP'},\n",
    " {'слово': 'классе', 'разбор': 'N'},\n",
    " {'слово': 'отмечать', 'разбор': 'V'},\n",
    " {'слово': 'было', 'разбор': 'V'},\n",
    " {'слово': 'не', 'разбор': 'PART'},\n",
    " {'слово': 'принято', 'разбор': 'V'},\n",
    " {'слово': 'считать', 'разбор': 'V'},\n",
    " {'слово': 'это', 'разбор': 'PART'},\n",
    " {'слово': 'злой', 'разбор': 'A'},\n",
    " {'слово': 'волей', 'разбор': 'N'},\n",
    " {'слово': 'или', 'разбор': 'CONJ'},\n",
    " {'слово': 'намеренным', 'разбор': 'A'},\n",
    " {'слово': 'вредительством', 'разбор': 'N'},\n",
    " {'слово': 'не', 'разбор': 'PART'},\n",
    " {'слово': 'было', 'разбор': 'V'},\n",
    " {'слово': 'причин', 'разбор': 'N'},\n",
    " {'слово': 'по', 'разбор': 'PREP'},\n",
    " {'слово': 'крайней', 'разбор': 'A'},\n",
    " {'слово': 'мере', 'разбор': 'N'},\n",
    " {'слово': 'тех', 'разбор': 'PRON'},\n",
    " {'слово': 'которые', 'разбор': 'A'},\n",
    " {'слово': 'можно', 'разбор': 'A'},\n",
    " {'слово': 'было', 'разбор': 'V'},\n",
    " {'слово': 'бы', 'разбор': 'PART'},\n",
    " {'слово': 'привести', 'разбор': 'V'},\n",
    " {'слово': 'в', 'разбор': 'PREP'},\n",
    " {'слово': 'пример', 'разбор': 'N'},\n",
    " {'слово': 'но', 'разбор': 'CONJ'},\n",
    " {'слово': 'это', 'разбор': 'PRON'},\n",
    " {'слово': 'все', 'разбор': 'PRON'},\n",
    " {'слово': 'равно', 'разбор': 'A'},\n",
    " {'слово': 'казалось', 'разбор': 'V'},\n",
    " {'слово': 'странноватым', 'разбор': 'A'},\n",
    " {'слово': 'достаточно', 'разбор': 'A'},\n",
    " {'слово': 'чтобы', 'разбор': 'CONJ'},\n",
    " {'слово': 'задуматься', 'разбор': 'V'},\n",
    " {'слово': 'и', 'разбор': 'CONJ'},\n",
    " {'слово': 'по-новому', 'разбор': 'A'},\n",
    " {'слово': 'оценить', 'разбор': 'V'},\n",
    " {'слово': 'по-старому', 'разбор': 'A'},\n",
    " {'слово': 'организованный', 'разбор': 'A'},\n",
    " {'слово': 'порядок', 'разбор': 'N'},\n",
    " {'слово': 'несмотря', 'разбор': 'PREP'},\n",
    " {'слово': 'на', 'разбор': 'PREP'},\n",
    " {'слово': 'то', 'разбор': 'PRON'},\n",
    " {'слово': 'что', 'разбор': 'CONJ'},\n",
    " {'слово': 'лишь', 'разбор': 'PART'},\n",
    " {'слово': 'прыгнув', 'разбор': 'V'},\n",
    " {'слово': 'можно', 'разбор': 'A'},\n",
    " {'слово': 'было', 'разбор': 'V'},\n",
    " {'слово': 'получить', 'разбор': 'V'},\n",
    " {'слово': 'замечание', 'разбор': 'N'},\n",
    " {'слово': 'из-за', 'разбор': 'PREP'},\n",
    " {'слово': 'пропусков', 'разбор': 'N'},\n",
    " {'слово': 'завучиха', 'разбор': 'N'},\n",
    " {'слово': 'не', 'разбор': 'PART'},\n",
    " {'слово': 'возникала', 'разбор': 'V'},\n",
    " {'слово': 'школьный', 'разбор': 'A'},\n",
    " {'слово': 'трудовик', 'разбор': 'N'},\n",
    " {'слово': 'иван', 'разбор': 'N'},\n",
    " {'слово': 'пытался', 'разбор': 'V'},\n",
    " {'слово': 'было', 'разбор': 'PART'},\n",
    " {'слово': 'возразить', 'разбор': 'V'},\n",
    " {'слово': 'дескать', 'разбор': 'A'},\n",
    " {'слово': 'все', 'разбор': 'PRON'},\n",
    " {'слово': 'не', 'разбор': 'PART'},\n",
    " {'слово': 'по', 'разбор': 'PREP'},\n",
    " {'слово': 'госту', 'разбор': 'N'},\n",
    " {'слово': 'и', 'разбор': 'CONJ'},\n",
    " {'слово': 'минобр', 'разбор': 'N'},\n",
    " {'слово': 'будет', 'разбор': 'V'},\n",
    " {'слово': 'недобр', 'разбор': 'A'},\n",
    " {'слово': 'но', 'разбор': 'CONJ'},\n",
    " {'слово': 'куда', 'разбор': 'A'},\n",
    " {'слово': 'там', 'разбор': 'A'},\n",
    " {'слово': 'в', 'разбор': 'PREP'},\n",
    " {'слово': 'принципе', 'разбор': 'N'},\n",
    " {'слово': 'пока', 'разбор': 'CONJ'},\n",
    " {'слово': 'никто', 'разбор': 'PRON'},\n",
    " {'слово': 'не', 'разбор': 'PART'},\n",
    " {'слово': 'косячил', 'разбор': 'V'},\n",
    " {'слово': 'несуразица', 'разбор': 'N'},\n",
    " {'слово': 'никого', 'разбор': 'PRON'},\n",
    " {'слово': 'особо', 'разбор': 'A'},\n",
    " {'слово': 'не', 'разбор': 'PART'},\n",
    " {'слово': 'трогала', 'разбор': 'V'},\n",
    " {'слово': 'де-юре', 'разбор': 'A'},\n",
    " {'слово': 'все', 'разбор': 'PRON'},\n",
    " {'слово': 'было', 'разбор': 'V'},\n",
    " {'слово': 'чин', 'разбор': 'N'},\n",
    " {'слово': 'по', 'разбор': 'PREP'},\n",
    " {'слово': 'чину', 'разбор': 'N'},\n",
    " {'слово': 'де-факто', 'разбор': 'A'},\n",
    " {'слово': 'же', 'разбор': 'PART'},\n",
    " {'слово': 'дисциплина', 'разбор': 'N'},\n",
    " {'слово': 'страдала', 'разбор': 'V'},\n",
    " {'слово': 'нещадно', 'разбор': 'A'},\n",
    " {'слово': 'и', 'разбор': 'CONJ'},\n",
    " {'слово': 'даже', 'разбор': 'PART'},\n",
    " {'слово': 'разговоры', 'разбор': 'N'},\n",
    " {'слово': 'тет-а-тет', 'разбор': 'A'},\n",
    " {'слово': 'в', 'разбор': 'PREP'},\n",
    " {'слово': 'директорской', 'разбор': 'A'},\n",
    " {'слово': 'приемной', 'разбор': 'N'},\n",
    " {'слово': 'не', 'разбор': 'PART'},\n",
    " {'слово': 'сильно', 'разбор': 'A'},\n",
    " {'слово': 'спасали', 'разбор': 'V'},\n",
    " {'слово': 'неуклонно', 'разбор': 'A'},\n",
    " {'слово': 'падающий', 'разбор': 'A'},\n",
    " {'слово': 'псевдоавторитет', 'разбор': 'N'},\n",
    " {'слово': 'учительского', 'разбор': 'A'},\n",
    " {'слово': 'состава', 'разбор': 'N'},\n",
    " {'слово': 'ой-ой-ой', 'разбор': 'N'},\n",
    " {'слово': 'зимой', 'разбор': 'N'},\n",
    " {'слово': 'было', 'разбор': 'V'},\n",
    " {'слово': 'чуть', 'разбор': 'A'},\n",
    " {'слово': 'лучше', 'разбор': 'A'},\n",
    " {'слово': 'но', 'разбор': 'CONJ'},\n",
    " {'слово': 'за', 'разбор': 'PREP'},\n",
    " {'слово': 'зимой', 'разбор': 'N'},\n",
    " {'слово': 'пришла', 'разбор': 'V'},\n",
    " {'слово': 'весна', 'разбор': 'N'},\n",
    " {'слово': 'и', 'разбор': 'CONJ'},\n",
    " {'слово': 'тут', 'разбор': 'A'},\n",
    " {'слово': 'стало', 'разбор': 'V'},\n",
    " {'слово': 'интереснее', 'разбор': 'A'},\n",
    " {'слово': 'в', 'разбор': 'PREP'},\n",
    " {'слово': 'апреле', 'разбор': 'N'},\n",
    " {'слово': 'появился', 'разбор': 'V'},\n",
    " {'слово': 'не', 'разбор': 'PART'},\n",
    " {'слово': 'только', 'разбор': 'PART'},\n",
    " {'слово': 'запах', 'разбор': 'N'},\n",
    " {'слово': 'ландышей', 'разбор': 'N'},\n",
    " {'слово': 'апрель', 'разбор': 'N'},\n",
    " {'слово': 'запах', 'разбор': 'V'},\n",
    " {'слово': 'проблемами', 'разбор': 'N'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tags(first_tag):\n",
    "    if first_tag in {'ADV', 'ADJ', 'A', 'ADJS', 'ADJF', 'COMP', 'PRTF', 'PRTS', 'ADVB', 'NUM', 'NUMR', 'ANUM', 'PRED', 'ADVPRO', 'APRO', 'COM'}:\n",
    "        last_tag = 'A'\n",
    "    elif first_tag in {'NOUN', 'S', 'PROPN', 'INTJ'}:\n",
    "        last_tag = 'N'    \n",
    "    elif first_tag in {'VERB', 'V', 'INFN', 'GRND', 'AUX'}:\n",
    "        last_tag = 'V'    \n",
    "    elif first_tag in {'SCONJ', 'CCONJ', 'CONJ'}:\n",
    "        last_tag = 'CONJ'    \n",
    "    elif first_tag in {'ADP', 'PR', 'PREP'}:\n",
    "        last_tag = 'PREP'    \n",
    "    elif first_tag in {'PART', 'PRCL'}:\n",
    "        last_tag = 'PART'\n",
    "    elif first_tag in {'DET', 'PRON', 'NPRO', 'SPRO'}:\n",
    "        last_tag = 'PRON'  \n",
    "    else:\n",
    "        last_tag = first_tag\n",
    "        \n",
    "        \n",
    "    return last_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "#syntax_parser = NewsSyntaxParser(emb)\n",
    "#ner_tagger = NewsNERTagger(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Doc(TEXT1)\n",
    "doc.segment(segmenter)\n",
    "#display(doc.tokens[:5])\n",
    "#display(doc.sents[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.tag_morph(morph_tagger)\n",
    "#display(doc.tokens[:5])\n",
    "#doc.sents[0].morph.print()\n",
    "natasha_result = []\n",
    "poses = []\n",
    "for sent in doc.sents:\n",
    "    for mtoken in sent.morph.tokens:\n",
    "        t_dict = {}\n",
    "        t_dict['слово'] = mtoken.text.lower()\n",
    "        t_dict['разбор'] = convert_tags(mtoken.pos)\n",
    "        if not t_dict['разбор'] == 'PUNCT':\n",
    "            natasha_result.append(t_dict)\n",
    "            poses.append(t_dict['разбор'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'слово': 'отсутствующих', 'разбор': 'A'},\n",
       " {'слово': 'людей', 'разбор': 'N'},\n",
       " {'слово': 'в', 'разбор': 'PREP'},\n",
       " {'слово': 'классе', 'разбор': 'N'},\n",
       " {'слово': 'отмечать', 'разбор': 'V'}]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natasha_result[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pymorphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Отсутствующих', 'людей', 'в', 'классе', 'отмечать', 'было', 'не', 'принято']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(TEXT1)\n",
    "print(tokens[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "pymorphy_result = []\n",
    "\n",
    "for number, token in enumerate(tokens):\n",
    "    words = morph.parse(token)\n",
    "    form = words[0]\n",
    "    this_word = {}\n",
    "    this_word['слово'] = form.word\n",
    "    this_word['разбор'] = convert_tags(form.tag.POS)\n",
    "    if this_word['разбор'] != None:\n",
    "        pymorphy_result.append(this_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'слово': 'отсутствующих', 'разбор': 'A'},\n",
       " {'слово': 'людей', 'разбор': 'N'},\n",
       " {'слово': 'в', 'разбор': 'PREP'},\n",
       " {'слово': 'классе', 'разбор': 'N'},\n",
       " {'слово': 'отмечать', 'разбор': 'V'}]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pymorphy_result[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'analysis': [{'lex': 'отсутствующий', 'wt': 0.008304714066, 'gr': 'A,полн=(пр,мн|род,мн|вин,мн,од)'}], 'text': 'Отсутствующих'}, {'text': ' '}, {'analysis': [{'lex': 'человек', 'wt': 1, 'gr': 'S,муж,од=(вин,мн|род,мн)'}], 'text': 'людей'}, {'text': ' '}, {'analysis': [{'lex': 'в', 'wt': 0.9999917878, 'gr': 'PR='}], 'text': 'в'}]\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "\n",
    "full_stem = m.analyze(TEXT1)\n",
    "print(full_stem[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_result = []\n",
    "\n",
    "for word in full_stem:\n",
    "    if word.get('analysis') != None:\n",
    "        mystem_dict = {}\n",
    "        mystem_dict['слово'] = word['text'].lower()\n",
    "        mystem_dict['разбор'] = convert_tags(word['analysis'][0]['gr'].split('=')[0].split(',')[0])\n",
    "        mystem_result.append(mystem_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'слово': 'отсутствующих', 'разбор': 'A'},\n",
       " {'слово': 'людей', 'разбор': 'N'},\n",
       " {'слово': 'в', 'разбор': 'PREP'},\n",
       " {'слово': 'классе', 'разбор': 'N'},\n",
       " {'слово': 'отмечать', 'разбор': 'V'}]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_result[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе функция выдаёт не только accuracy, но и расхождение с эталоном"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(natasha_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mystem_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pymorphy_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ура, количество токенов одинаковое, всё хорошо!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_acc(any_result, RESULT):\n",
    "    detected_result = []\n",
    "    real_result = []\n",
    "    errors = []\n",
    "    for i, word in enumerate(any_result):\n",
    "        if word == RESULT[i]:\n",
    "            detected_result.append('pos')\n",
    "        else:\n",
    "            detected_result.append('neg')\n",
    "            errors.append([word, RESULT[i]])\n",
    "        real_result.append('pos')\n",
    "        \n",
    "    acc = accuracy_score(detected_result, real_result)\n",
    "    return acc, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9130434782608695,\n",
       " [[{'слово': 'которые', 'разбор': 'PRON'},\n",
       "   {'слово': 'которые', 'разбор': 'A'}],\n",
       "  [{'слово': 'бы', 'разбор': 'V'}, {'слово': 'бы', 'разбор': 'PART'}],\n",
       "  [{'слово': 'организованный', 'разбор': 'V'},\n",
       "   {'слово': 'организованный', 'разбор': 'A'}],\n",
       "  [{'слово': 'несмотря', 'разбор': 'A'},\n",
       "   {'слово': 'несмотря', 'разбор': 'PREP'}],\n",
       "  [{'слово': 'прыгнув', 'разбор': 'N'}, {'слово': 'прыгнув', 'разбор': 'V'}],\n",
       "  [{'слово': 'было', 'разбор': 'V'}, {'слово': 'было', 'разбор': 'PART'}],\n",
       "  [{'слово': 'пока', 'разбор': 'A'}, {'слово': 'пока', 'разбор': 'CONJ'}],\n",
       "  [{'слово': 'несуразица', 'разбор': 'V'},\n",
       "   {'слово': 'несуразица', 'разбор': 'N'}],\n",
       "  [{'слово': 'тет-а-тет', 'разбор': 'V'},\n",
       "   {'слово': 'тет-а-тет', 'разбор': 'A'}],\n",
       "  [{'слово': 'директорской', 'разбор': 'N'},\n",
       "   {'слово': 'директорской', 'разбор': 'A'}],\n",
       "  [{'слово': 'падающий', 'разбор': 'V'}, {'слово': 'падающий', 'разбор': 'A'}],\n",
       "  [{'слово': 'запах', 'разбор': 'N'}, {'слово': 'запах', 'разбор': 'V'}]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_acc(natasha_result, RESULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9710144927536232,\n",
       " [[{'слово': 'тех', 'разбор': 'A'}, {'слово': 'тех', 'разбор': 'PRON'}],\n",
       "  [{'слово': 'несмотря', 'разбор': 'A'},\n",
       "   {'слово': 'несмотря', 'разбор': 'PREP'}],\n",
       "  [{'слово': 'падающий', 'разбор': 'V'}, {'слово': 'падающий', 'разбор': 'A'}],\n",
       "  [{'слово': 'запах', 'разбор': 'N'}, {'слово': 'запах', 'разбор': 'V'}]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_acc(mystem_result, RESULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.855072463768116,\n",
       " [[{'слово': 'принято', 'разбор': 'A'}, {'слово': 'принято', 'разбор': 'V'}],\n",
       "  [{'слово': 'волей', 'разбор': 'A'}, {'слово': 'волей', 'разбор': 'N'}],\n",
       "  [{'слово': 'тех', 'разбор': 'A'}, {'слово': 'тех', 'разбор': 'PRON'}],\n",
       "  [{'слово': 'это', 'разбор': 'PART'}, {'слово': 'это', 'разбор': 'PRON'}],\n",
       "  [{'слово': 'все', 'разбор': 'A'}, {'слово': 'все', 'разбор': 'PRON'}],\n",
       "  [{'слово': 'равно', 'разбор': 'CONJ'}, {'слово': 'равно', 'разбор': 'A'}],\n",
       "  [{'слово': 'казалось', 'разбор': 'CONJ'},\n",
       "   {'слово': 'казалось', 'разбор': 'V'}],\n",
       "  [{'слово': 'то', 'разбор': 'CONJ'}, {'слово': 'то', 'разбор': 'PRON'}],\n",
       "  [{'слово': 'было', 'разбор': 'V'}, {'слово': 'было', 'разбор': 'PART'}],\n",
       "  [{'слово': 'дескать', 'разбор': 'CONJ'},\n",
       "   {'слово': 'дескать', 'разбор': 'A'}],\n",
       "  [{'слово': 'все', 'разбор': 'A'}, {'слово': 'все', 'разбор': 'PRON'}],\n",
       "  [{'слово': 'минобр', 'разбор': 'A'}, {'слово': 'минобр', 'разбор': 'N'}],\n",
       "  [{'слово': 'куда', 'разбор': 'N'}, {'слово': 'куда', 'разбор': 'A'}],\n",
       "  [{'слово': 'пока', 'разбор': 'A'}, {'слово': 'пока', 'разбор': 'CONJ'}],\n",
       "  [{'слово': 'все', 'разбор': 'A'}, {'слово': 'все', 'разбор': 'PRON'}],\n",
       "  [{'слово': 'приёмной', 'разбор': 'A'}, {'слово': 'приемной', 'разбор': 'N'}],\n",
       "  [{'слово': 'зимой', 'разбор': 'A'}, {'слово': 'зимой', 'разбор': 'N'}],\n",
       "  [{'слово': 'зимой', 'разбор': 'A'}, {'слово': 'зимой', 'разбор': 'N'}],\n",
       "  [{'слово': 'пришла', 'разбор': 'A'}, {'слово': 'пришла', 'разбор': 'V'}],\n",
       "  [{'слово': 'запах', 'разбор': 'N'}, {'слово': 'запах', 'разбор': 'V'}]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_acc(pymorphy_result, RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Английский язык"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT2 = '''The big set up was set to happen at exactly 7 o'clock - though the clock in question would probably be broken, \n",
    "    as would be all clocks in this godforsaken magical town. The citizens were, of course, nonplussed, as in \"unperturbed \n",
    "    and not ashamed of it\", but you as an impostor were very, very cautious - and kinda angry. Life here had its ups and \n",
    "    downs, certainly, but the well in your garden was, well...not one of the ups, for sure, more like \"lower than lows\", \n",
    "    whatever that would mean. Without further ado, you were on edge - due to the clocks, the well, and all the little \n",
    "    thingies that made you blood burn with barely contained anger. But, hey. As the saying goes, no rose without thorns, \n",
    "    right?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT2 = [{'слово': 'The', 'разбор': 'DET'},\n",
    " {'слово': 'big', 'разбор': 'A'},\n",
    " {'слово': 'set', 'разбор': 'N'},\n",
    " {'слово': 'up', 'разбор': 'N'},\n",
    " {'слово': 'was', 'разбор': 'V'},\n",
    " {'слово': 'set', 'разбор': 'V'},\n",
    " {'слово': 'to', 'разбор': 'PART'},\n",
    " {'слово': 'happen', 'разбор': 'V'},\n",
    " {'слово': 'at', 'разбор': 'PREP'},\n",
    " {'слово': 'exactly', 'разбор': 'A'},\n",
    " {'слово': '7', 'разбор': 'NUM'},\n",
    " {'слово': \"o'clock\", 'разбор': 'N'},\n",
    " {'слово': 'though', 'разбор': 'CONJ'},\n",
    " {'слово': 'the', 'разбор': 'DET'},\n",
    " {'слово': 'clock', 'разбор': 'N'},\n",
    " {'слово': 'in', 'разбор': 'PREP'},\n",
    " {'слово': 'question', 'разбор': 'N'},\n",
    " {'слово': 'would', 'разбор': 'V'},\n",
    " {'слово': 'probably', 'разбор': 'A'},\n",
    " {'слово': 'be', 'разбор': 'V'},\n",
    " {'слово': 'broken', 'разбор': 'V'},\n",
    " {'слово': 'as', 'разбор': 'CONJ'},\n",
    " {'слово': 'would', 'разбор': 'V'},\n",
    " {'слово': 'be', 'разбор': 'V'},\n",
    " {'слово': 'all', 'разбор': 'DET'},\n",
    " {'слово': 'clocks', 'разбор': 'N'},\n",
    " {'слово': 'in', 'разбор': 'PREP'},\n",
    " {'слово': 'this', 'разбор': 'DET'},\n",
    " {'слово': 'godforsaken', 'разбор': 'A'},\n",
    " {'слово': 'magical', 'разбор': 'A'},\n",
    " {'слово': 'town', 'разбор': 'N'},\n",
    " {'слово': 'The', 'разбор': 'DET'},\n",
    " {'слово': 'citizens', 'разбор': 'N'},\n",
    " {'слово': 'were', 'разбор': 'V'},\n",
    " {'слово': 'of', 'разбор': 'A'},\n",
    " {'слово': 'course', 'разбор': 'A'},\n",
    " {'слово': 'nonplussed', 'разбор': 'V'},\n",
    " {'слово': 'as', 'разбор': 'CONJ'},\n",
    " {'слово': 'in', 'разбор': 'PREP'},\n",
    " {'слово': 'unperturbed', 'разбор': 'A'},\n",
    " {'слово': 'and', 'разбор': 'CONJ'},\n",
    " {'слово': 'not', 'разбор': 'PART'},\n",
    " {'слово': 'ashamed', 'разбор': 'A'},\n",
    " {'слово': 'of', 'разбор': 'PREP'},\n",
    " {'слово': 'it', 'разбор': 'PRON'},\n",
    " {'слово': 'but', 'разбор': 'CONJ'},\n",
    " {'слово': 'you', 'разбор': 'PRON'},\n",
    " {'слово': 'as', 'разбор': 'PREP'},\n",
    " {'слово': 'an', 'разбор': 'DET'},\n",
    " {'слово': 'impostor', 'разбор': 'N'},\n",
    " {'слово': 'were', 'разбор': 'V'},\n",
    " {'слово': 'very', 'разбор': 'A'},\n",
    " {'слово': 'very', 'разбор': 'A'},\n",
    " {'слово': 'cautious', 'разбор': 'A'},\n",
    " {'слово': 'and', 'разбор': 'CONJ'},\n",
    " {'слово': 'kinda', 'разбор': 'A'},\n",
    " {'слово': 'angry', 'разбор': 'A'},\n",
    " {'слово': 'Life', 'разбор': 'N'},\n",
    " {'слово': 'here', 'разбор': 'A'},\n",
    " {'слово': 'had', 'разбор': 'V'},\n",
    " {'слово': 'its', 'разбор': 'PRON'},\n",
    " {'слово': 'ups', 'разбор': 'N'},\n",
    " {'слово': 'and', 'разбор': 'CONJ'},\n",
    " {'слово': 'downs', 'разбор': 'N'},\n",
    " {'слово': 'certainly', 'разбор': 'A'},\n",
    " {'слово': 'but', 'разбор': 'CONJ'},\n",
    " {'слово': 'the', 'разбор': 'DET'},\n",
    " {'слово': 'well', 'разбор': 'N'},\n",
    " {'слово': 'in', 'разбор': 'PREP'},\n",
    " {'слово': 'your', 'разбор': 'PRON'},\n",
    " {'слово': 'garden', 'разбор': 'N'},\n",
    " {'слово': 'was', 'разбор': 'V'},\n",
    " {'слово': 'well', 'разбор': 'INTJ'},\n",
    " {'слово': 'not', 'разбор': 'PART'},\n",
    " {'слово': 'one', 'разбор': 'NUM'},\n",
    " {'слово': 'of', 'разбор': 'PREP'},\n",
    " {'слово': 'the', 'разбор': 'DET'},\n",
    " {'слово': 'ups', 'разбор': 'N'},\n",
    " {'слово': 'for', 'разбор': 'PREP'},\n",
    " {'слово': 'sure', 'разбор': 'A'},\n",
    " {'слово': 'more', 'разбор': 'A'},\n",
    " {'слово': 'like', 'разбор': 'PREP'},\n",
    " {'слово': 'lower', 'разбор': 'A'},\n",
    " {'слово': 'than', 'разбор': 'CONJ'},\n",
    " {'слово': 'lows', 'разбор': 'N'},\n",
    " {'слово': 'whatever', 'разбор': 'PRON'},\n",
    " {'слово': 'that', 'разбор': 'PRON'},\n",
    " {'слово': 'would', 'разбор': 'V'},\n",
    " {'слово': 'mean', 'разбор': 'V'},\n",
    " {'слово': 'Without', 'разбор': 'PREP'},\n",
    " {'слово': 'further', 'разбор': 'A'},\n",
    " {'слово': 'ado', 'разбор': 'N'},\n",
    " {'слово': 'you', 'разбор': 'PRON'},\n",
    " {'слово': 'were', 'разбор': 'V'},\n",
    " {'слово': 'on', 'разбор': 'PREP'},\n",
    " {'слово': 'edge', 'разбор': 'N'},\n",
    " {'слово': 'due', 'разбор': 'PREP'},\n",
    " {'слово': 'to', 'разбор': 'PREP'},\n",
    " {'слово': 'the', 'разбор': 'DET'},\n",
    " {'слово': 'clocks', 'разбор': 'N'},\n",
    " {'слово': 'the', 'разбор': 'DET'},\n",
    " {'слово': 'well', 'разбор': 'A'},\n",
    " {'слово': 'and', 'разбор': 'CONJ'},\n",
    " {'слово': 'all', 'разбор': 'DET'},\n",
    " {'слово': 'the', 'разбор': 'DET'},\n",
    " {'слово': 'little', 'разбор': 'A'},\n",
    " {'слово': 'thingies', 'разбор': 'N'},\n",
    " {'слово': 'that', 'разбор': 'CONJ'},\n",
    " {'слово': 'made', 'разбор': 'V'},\n",
    " {'слово': 'you', 'разбор': 'PRON'},\n",
    " {'слово': 'blood', 'разбор': 'N'},\n",
    " {'слово': 'burn', 'разбор': 'V'},\n",
    " {'слово': 'with', 'разбор': 'PREP'},\n",
    " {'слово': 'barely', 'разбор': 'A'},\n",
    " {'слово': 'contained', 'разбор': 'V'},\n",
    " {'слово': 'anger', 'разбор': 'N'},\n",
    " {'слово': 'But', 'разбор': 'CONJ'},\n",
    " {'слово': 'hey', 'разбор': 'INTJ'},\n",
    " {'слово': 'As', 'разбор': 'CONJ'},\n",
    " {'слово': 'the', 'разбор': 'DET'},\n",
    " {'слово': 'saying', 'разбор': 'N'},\n",
    " {'слово': 'goes', 'разбор': 'V'},\n",
    " {'слово': 'no', 'разбор': 'DET'},\n",
    " {'слово': 'rose', 'разбор': 'N'},\n",
    " {'слово': 'without', 'разбор': 'PREP'},\n",
    " {'слово': 'thorns', 'разбор': 'N'},\n",
    " {'слово': 'right', 'разбор': 'A'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_eng_tags(first_tag):\n",
    "    if first_tag in {'ADJ', 'ADV', 'RB', 'RBR', 'RBS', 'JJ', 'JJR', 'JJS', }:\n",
    "        last_tag = 'A'\n",
    "    elif first_tag in {'PROPN', 'NOUN', 'NN', 'NNS', 'NNP', 'NNPS'}:\n",
    "        last_tag = 'N'    \n",
    "    elif first_tag in  {'VERB', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'MD', 'AUX'}:\n",
    "        last_tag = 'V'    \n",
    "    elif first_tag in {'SCONJ', 'CCONJ', 'CONJ', 'CC', 'PCONJ'}:\n",
    "        last_tag = 'CONJ'    \n",
    "    elif first_tag in {'ADP', 'TO', 'IN'}:\n",
    "        last_tag = 'PREP'    \n",
    "    elif first_tag in {'PART', 'POS', 'RP'}:\n",
    "        last_tag = 'PART'\n",
    "    elif first_tag in {'PRON', 'WDT', 'WP', 'WP$', 'WRB', 'PRP', 'PRP$', 'EX'}:\n",
    "        last_tag = 'PRON'  \n",
    "    elif first_tag in {'DT', 'DET', 'PDT'}:\n",
    "        last_tag = 'DET'  \n",
    "    elif first_tag in {'NUM', 'CD'}:\n",
    "        last_tag = 'NUM'  \n",
    "    elif first_tag in {'INTJ', 'UH'}:\n",
    "        last_tag = 'INTJ'  \n",
    "    else:\n",
    "        last_tag = 'PUNCT'\n",
    "        \n",
    "        \n",
    "    return last_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Sentence 0 --\n",
      "The\tDET\n",
      "big\tADJ\n",
      "set\tNOUN\n",
      "up\tADP\n",
      "was\tAUX\n",
      "set\tVERB\n",
      "to\tPART\n",
      "happen\tVERB\n",
      "at\tADP\n",
      "exactly\tADV\n",
      "7\tNUM\n",
      "o’clock\tNOUN\n",
      "-\tPUNCT\n",
      "though\tSCONJ\n",
      "the\tDET\n",
      "clock\tNOUN\n",
      "in\tADP\n",
      "question\tNOUN\n",
      "would\tVERB\n",
      "probably\tADV\n",
      "be\tAUX\n",
      "broken\tVERB\n",
      ",\tPUNCT\n",
      "\n",
      "    \tSPACE\n",
      "as\tSCONJ\n",
      "would\tVERB\n",
      "be\tAUX\n",
      "all\tDET\n",
      "clocks\tNOUN\n",
      "in\tADP\n",
      "this\tDET\n",
      "godforsaken\tADJ\n",
      "magical\tADJ\n",
      "town\tNOUN\n",
      ".\tPUNCT\n",
      "\n",
      "-- Sentence 1 --\n",
      "The\tDET\n",
      "citizens\tNOUN\n",
      "were\tAUX\n",
      ",\tPUNCT\n",
      "of\tADP\n",
      "course\tNOUN\n",
      ",\tPUNCT\n",
      "nonplussed\tVERB\n",
      ",\tPUNCT\n",
      "as\tSCONJ\n",
      "in\tADP\n",
      "“\tPUNCT\n",
      "unperturbed\tADJ\n",
      "\n",
      "    \tSPACE\n",
      "and\tCCONJ\n",
      "not\tPART\n",
      "ashamed\tADJ\n",
      "of\tADP\n",
      "it\tPRON\n",
      "”\tPUNCT\n",
      ",\tPUNCT\n",
      "but\tCCONJ\n",
      "you\tPRON\n",
      "as\tSCONJ\n",
      "an\tDET\n",
      "impostor\tNOUN\n",
      "were\tAUX\n",
      "very\tADV\n",
      ",\tPUNCT\n",
      "very\tADV\n",
      "cautious\tADJ\n",
      "-\tPUNCT\n",
      "and\tCCONJ\n",
      "kinda\tADV\n",
      "angry\tADJ\n",
      ".\tPUNCT\n",
      "\n",
      "-- Sentence 2 --\n",
      "Life\tNOUN\n",
      "here\tADV\n",
      "had\tAUX\n",
      "its\tDET\n",
      "ups\tNOUN\n",
      "and\tCCONJ\n",
      "\n",
      "    \tSPACE\n",
      "downs\tNOUN\n",
      ",\tPUNCT\n",
      "certainly\tADV\n",
      ",\tPUNCT\n",
      "but\tCCONJ\n",
      "the\tDET\n",
      "well\tNOUN\n",
      "in\tADP\n",
      "your\tDET\n",
      "garden\tNOUN\n",
      "was\tAUX\n",
      ",\tPUNCT\n",
      "well\tINTJ\n",
      "...\tPUNCT\n",
      "not\tPART\n",
      "one\tNUM\n",
      "of\tADP\n",
      "the\tDET\n",
      "ups\tNOUN\n",
      ",\tPUNCT\n",
      "for\tADP\n",
      "sure\tADJ\n",
      ",\tPUNCT\n",
      "more\tADV\n",
      "like\tSCONJ\n",
      "“\tPUNCT\n",
      "lower\tADJ\n",
      "than\tSCONJ\n",
      "lows\tNOUN\n",
      "”\tPUNCT\n",
      ",\tPUNCT\n",
      "\n",
      "    \tSPACE\n",
      "whatever\tDET\n",
      "that\tDET\n",
      "would\tVERB\n",
      "mean\tVERB\n",
      ".\tPUNCT\n",
      "\n",
      "-- Sentence 3 --\n",
      "Without\tADP\n",
      "further\tADJ\n",
      "ado\tNOUN\n",
      ",\tPUNCT\n",
      "you\tPRON\n",
      "were\tAUX\n",
      "on\tADP\n",
      "edge\tNOUN\n",
      "-\tPUNCT\n",
      "due\tADP\n",
      "to\tADP\n",
      "the\tDET\n",
      "clocks\tNOUN\n",
      ",\tPUNCT\n",
      "the\tDET\n",
      "well\tADJ\n",
      ",\tPUNCT\n",
      "and\tCCONJ\n",
      "all\tDET\n",
      "the\tDET\n",
      "little\tADJ\n",
      "\n",
      "    \tSPACE\n",
      "thingies\tNOUN\n",
      "that\tDET\n",
      "made\tVERB\n",
      "you\tPRON\n",
      "blood\tNOUN\n",
      "burn\tVERB\n",
      "with\tADP\n",
      "barely\tADV\n",
      "contained\tVERB\n",
      "anger\tNOUN\n",
      ".\tPUNCT\n",
      "\n",
      "-- Sentence 4 --\n",
      "But\tCCONJ\n",
      ",\tPUNCT\n",
      "hey\tINTJ\n",
      ".\tPUNCT\n",
      "\n",
      "-- Sentence 5 --\n",
      "As\tSCONJ\n",
      "the\tDET\n",
      "saying\tNOUN\n",
      "goes\tVERB\n",
      ",\tPUNCT\n",
      "no\tDET\n",
      "rose\tVERB\n",
      "without\tADP\n",
      "thorns\tNOUN\n",
      ",\tPUNCT\n",
      "\n",
      "    \tSPACE\n",
      "right\tADJ\n",
      "?\tPUNCT\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(TEXT2)\n",
    "spacy_result = []\n",
    "for sent in doc.sents:\n",
    "    for t in sent:\n",
    "        word = {}\n",
    "        word['слово'] = t.text\n",
    "        word['разбор'] = convert_eng_tags(t.pos_)\n",
    "        if word['разбор'] != 'PUNCT':\n",
    "            spacy_result.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spacy_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осторожно, долгая загрузка. Зато теги хороши!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-18 20:01:43,291 https://nlp.informatik.hu-berlin.de/resources/models/multi-pos/pos-multi-v0.1.pt not found in cache, downloading to C:\\Users\\M\\AppData\\Local\\Temp\\tmp35vs92ee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 314055714/314055714 [1:23:39<00:00, 62565.23B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-18 21:25:23,390 copying C:\\Users\\M\\AppData\\Local\\Temp\\tmp35vs92ee to cache at C:\\Users\\M\\.flair\\models\\pos-multi-v0.1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-18 21:25:27,162 removing temp file C:\\Users\\M\\AppData\\Local\\Temp\\tmp35vs92ee\n",
      "2020-10-18 21:25:27,298 loading file C:\\Users\\M\\.flair\\models\\pos-multi-v0.1.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger = SequenceTagger.load('pos-multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentence = Sentence(TEXT2)\n",
    "tagger.predict(sentence)\n",
    "\n",
    "#print(sentence)\n",
    "f_result = sentence.to_tagged_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_result = []\n",
    "for word in f_result.split('> '):\n",
    "    word = word.split(' <')\n",
    "    new_word = {}\n",
    "    new_word['слово'] = word[0]\n",
    "    new_word['разбор'] = convert_eng_tags(word[1].strip('>'))\n",
    "    if new_word['разбор'] != 'PUNCT':\n",
    "        flair_result.append(new_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flair_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\M\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'big', 'set', 'up', 'was', 'set', 'to', 'happen', 'at', 'exactly']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(TEXT2)\n",
    "\n",
    "print(tokens[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_result = []\n",
    "for word in nltk.pos_tag(tokens):\n",
    "    new_word = {}\n",
    "    new_word['слово'] = word[0]\n",
    "    new_word['разбор'] = convert_eng_tags(word[1])\n",
    "    if new_word['разбор'] != 'PUNCT':\n",
    "        nltk_result.append(new_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy для английского"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9133858267716536,\n",
       " [[{'слово': 'up', 'разбор': 'PREP'}, {'слово': 'up', 'разбор': 'N'}],\n",
       "  [{'слово': 'of', 'разбор': 'PREP'}, {'слово': 'of', 'разбор': 'A'}],\n",
       "  [{'слово': 'course', 'разбор': 'N'}, {'слово': 'course', 'разбор': 'A'}],\n",
       "  [{'слово': 'as', 'разбор': 'CONJ'}, {'слово': 'as', 'разбор': 'PREP'}],\n",
       "  [{'слово': 'its', 'разбор': 'DET'}, {'слово': 'its', 'разбор': 'PRON'}],\n",
       "  [{'слово': 'your', 'разбор': 'DET'}, {'слово': 'your', 'разбор': 'PRON'}],\n",
       "  [{'слово': 'like', 'разбор': 'CONJ'}, {'слово': 'like', 'разбор': 'PREP'}],\n",
       "  [{'слово': 'whatever', 'разбор': 'DET'},\n",
       "   {'слово': 'whatever', 'разбор': 'PRON'}],\n",
       "  [{'слово': 'that', 'разбор': 'DET'}, {'слово': 'that', 'разбор': 'PRON'}],\n",
       "  [{'слово': 'that', 'разбор': 'DET'}, {'слово': 'that', 'разбор': 'CONJ'}],\n",
       "  [{'слово': 'rose', 'разбор': 'V'}, {'слово': 'rose', 'разбор': 'N'}]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_acc(spacy_result, RESULT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9606299212598425,\n",
       " [[{'слово': 'well', 'разбор': 'A'}, {'слово': 'well', 'разбор': 'INTJ'}],\n",
       "  [{'слово': 'not', 'разбор': 'A'}, {'слово': 'not', 'разбор': 'PART'}],\n",
       "  [{'слово': 'than', 'разбор': 'PREP'}, {'слово': 'than', 'разбор': 'CONJ'}],\n",
       "  [{'слово': 'that', 'разбор': 'PRON'}, {'слово': 'that', 'разбор': 'CONJ'}],\n",
       "  [{'слово': 'right', 'разбор': 'INTJ'}, {'слово': 'right', 'разбор': 'A'}]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_acc(flair_result, RESULT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8110236220472441,\n",
       " [[{'слово': 'up', 'разбор': 'PART'}, {'слово': 'up', 'разбор': 'N'}],\n",
       "  [{'слово': 'to', 'разбор': 'PREP'}, {'слово': 'to', 'разбор': 'PART'}],\n",
       "  [{'слово': \"o'clock\", 'разбор': 'A'}, {'слово': \"o'clock\", 'разбор': 'N'}],\n",
       "  [{'слово': 'though', 'разбор': 'PREP'},\n",
       "   {'слово': 'though', 'разбор': 'CONJ'}],\n",
       "  [{'слово': 'as', 'разбор': 'PREP'}, {'слово': 'as', 'разбор': 'CONJ'}],\n",
       "  [{'слово': 'of', 'разбор': 'PREP'}, {'слово': 'of', 'разбор': 'A'}],\n",
       "  [{'слово': 'course', 'разбор': 'N'}, {'слово': 'course', 'разбор': 'A'}],\n",
       "  [{'слово': 'nonplussed', 'разбор': 'A'},\n",
       "   {'слово': 'nonplussed', 'разбор': 'V'}],\n",
       "  [{'слово': 'as', 'разбор': 'PREP'}, {'слово': 'as', 'разбор': 'CONJ'}],\n",
       "  [{'слово': 'not', 'разбор': 'A'}, {'слово': 'not', 'разбор': 'PART'}],\n",
       "  [{'слово': 'ashamed', 'разбор': 'V'}, {'слово': 'ashamed', 'разбор': 'A'}],\n",
       "  [{'слово': 'kinda', 'разбор': 'V'}, {'слово': 'kinda', 'разбор': 'A'}],\n",
       "  [{'слово': 'well', 'разбор': 'A'}, {'слово': 'well', 'разбор': 'N'}],\n",
       "  [{'слово': 'well', 'разбор': 'A'}, {'слово': 'well', 'разбор': 'INTJ'}],\n",
       "  [{'слово': 'than', 'разбор': 'PREP'}, {'слово': 'than', 'разбор': 'CONJ'}],\n",
       "  [{'слово': 'that', 'разбор': 'DET'}, {'слово': 'that', 'разбор': 'PRON'}],\n",
       "  [{'слово': 'due', 'разбор': 'A'}, {'слово': 'due', 'разбор': 'PREP'}],\n",
       "  [{'слово': 'well', 'разбор': 'N'}, {'слово': 'well', 'разбор': 'A'}],\n",
       "  [{'слово': 'that', 'разбор': 'PREP'}, {'слово': 'that', 'разбор': 'CONJ'}],\n",
       "  [{'слово': 'blood', 'разбор': 'V'}, {'слово': 'blood', 'разбор': 'N'}],\n",
       "  [{'слово': 'burn', 'разбор': 'N'}, {'слово': 'burn', 'разбор': 'V'}],\n",
       "  [{'слово': 'hey', 'разбор': 'A'}, {'слово': 'hey', 'разбор': 'INTJ'}],\n",
       "  [{'слово': 'As', 'разбор': 'PREP'}, {'слово': 'As', 'разбор': 'CONJ'}],\n",
       "  [{'слово': 'rose', 'разбор': 'V'}, {'слово': 'rose', 'разбор': 'N'}]])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_acc(nltk_result, RESULT2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, у нас получилось что-то, что показывает, что те библиотеки, которые больше ориентируются на контекст, точнее, но и они не идеальны."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
